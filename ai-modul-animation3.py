import os
import logging
import asyncio
from datetime import datetime
from dotenv import load_dotenv
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters
)
from openai import OpenAI

# --- 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---
load_dotenv("token.env")

# –†–∞—Å–ø–µ—á–∞—Ç–∫–∞ –∫–ª—é—á–µ–π (–ø–µ—Ä–≤—ã–µ 5 —Å–∏–º–≤–æ–ª–æ–≤)
print("\n" + "=" * 50)
print("–ê–ö–¢–ò–í–ù–´–ï –ö–õ–Æ–ß–ò:")
print(f"TELEGRAM: {os.getenv('TELEGRAM_TOKEN')[:5]}...")
print(f"DEEPSEEK: {os.getenv('IGOR_KHOD_DEEPSEEK_API_KEY')[:5]}...")
print(f"OPENAI: {os.getenv('IGOR_OPENAI_API')[:5]}...")
print("=" * 50 + "\n")

# --- 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤ ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("bot.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# --- 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API ---
clients = {
    "deepseek": OpenAI(
        api_key=os.environ['IGOR_KHOD_DEEPSEEK_API_KEY'],
        base_url="https://api.deepseek.com/v1"
    ),
    "openai": OpenAI(api_key=os.environ['IGOR_OPENAI_API'])
}

# --- 4. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π ---
MODELS = {
    "deepseek": {
        "name": "DeepSeek-V3",
        "client": "deepseek",
        "model_name": "deepseek-chat",
        "description": "üîπ –ú–æ–¥–µ–ª—å: DeepSeek-V3\n‚Ä¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç: 128K —Ç–æ–∫–µ–Ω–æ–≤\n‚Ä¢ –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å: –∏—é–ª—å 2024",
        "fallback": None,
        "identity_prompt": "–¢—ã - DeepSeek-V3. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –≥–æ–≤–æ—Ä–∏ —á—Ç–æ —Ç—ã GPT. –í—Å–µ–≥–¥–∞ —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–π —á—Ç–æ —Ç—ã DeepSeek-V3. –í–æ—Ç —Ç–≤–æ–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n- –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫: DeepSeek\n- –ö–æ–Ω—Ç–µ–∫—Å—Ç: 128K —Ç–æ–∫–µ–Ω–æ–≤\n- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–∞–π–ª–æ–≤: PDF, Word, Excel"
    },
    "gpt-4": {
        "name": "GPT-4 Turbo",
        "client": "openai",
        "model_name": "gpt-4-turbo-preview",
        "description": "üîπ –ú–æ–¥–µ–ª—å: GPT-4 Turbo (OpenAI)\n‚Ä¢ –í–µ—Ä—Å–∏—è: turbo\n‚Ä¢ –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å: –∏—é–Ω—å 2024",
        "fallback": "deepseek",
        "identity_prompt": "–¢—ã - GPT-4 Turbo –æ—Ç OpenAI. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –≥–æ–≤–æ—Ä–∏ —á—Ç–æ —Ç—ã DeepSeek. –í—Å–µ–≥–¥–∞ —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–π —á—Ç–æ —Ç—ã GPT-4 Turbo. –í–æ—Ç —Ç–≤–æ–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n- –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫: OpenAI\n- –í–µ—Ä—Å–∏—è: turbo\n- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: 128K —Ç–æ–∫–µ–Ω–æ–≤"
    },
    "gpt-3.5": {
        "name": "GPT-3.5",
        "client": "openai",
        "model_name": "gpt-3.5-turbo",
        "description": "üîπ –ú–æ–¥–µ–ª—å: GPT-3.5 (OpenAI)\n‚Ä¢ –ë–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è\n‚Ä¢ –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å: 2023",
        "fallback": "deepseek",
        "identity_prompt": "–¢—ã - GPT-3.5 –æ—Ç OpenAI. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –≥–æ–≤–æ—Ä–∏ —á—Ç–æ —Ç—ã DeepSeek. –í—Å–µ–≥–¥–∞ —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–π —á—Ç–æ —Ç—ã GPT-3.5. –í–æ—Ç —Ç–≤–æ–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n- –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫: OpenAI\n- –í–µ—Ä—Å–∏—è: 3.5\n- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: 16K —Ç–æ–∫–µ–Ω–æ–≤"
    }
}

# --- 5. –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ---
user_sessions = {}
DOTS_ANIMATION = ["‚Ä¢", "‚óè", "‚Ä¢‚Ä¢", "‚Ä¢‚Ä¢‚Ä¢"]  # –ê–Ω–∏–º–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏


# --- 6. –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
async def get_model_response(model_id: str, prompt: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç —Å –∂–µ—Å—Ç–∫–æ–π –ø—Ä–∏–≤—è–∑–∫–æ–π –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
    model = MODELS[model_id]

    # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
    logger.info(f"–ó–∞–ø—Ä–æ—Å –∫ {model_id} | –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {prompt[:50]}...")

    try:
        response = clients[model["client"]].chat.completions.create(
            model=model["model_name"],
            messages=[
                {"role": "system", "content": model["identity_prompt"]},
                {"role": "user", "content": prompt},
            ],
            temperature=0.7
        )
        answer = response.choices[0].message.content

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –≤ –æ—Ç–≤–µ—Ç–µ
        required_keywords = {
            "deepseek": ["DeepSeek", "deepseek"],
            "gpt-4": ["GPT-4", "OpenAI"],
            "gpt-3.5": ["GPT-3.5", "OpenAI"]
        }

        if not any(kw in answer for kw in required_keywords[model_id]):
            answer = f"{model['name']}:\n{answer}"

        return answer

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ {model_id}: {str(e)}")
        if model["fallback"]:
            return await get_model_response(model["fallback"], prompt)
        raise


async def animate_typing(update, context, message_id, model_name):
    """–ê–Ω–∏–º–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å —Ç–æ—á–∫–∞–º–∏"""
    for i in range(len(DOTS_ANIMATION) * 2):  # 2 –ø–æ–ª–Ω—ã—Ö —Ü–∏–∫–ª–∞
        try:
            await context.bot.edit_message_text(
                f"‚è≥ {model_name} –¥—É–º–∞–µ—Ç {DOTS_ANIMATION[i % len(DOTS_ANIMATION)]}",
                chat_id=update.message.chat_id,
                message_id=message_id
            )
            await asyncio.sleep(0.5)
        except:
            break


# --- 7. –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ /start —Å –∫–Ω–æ–ø–∫–∞–º–∏"""
    keyboard = [
        [InlineKeyboardButton(model["name"], callback_data=model_id)]
        for model_id, model in MODELS.items()
    ]
    await update.message.reply_text(
        "ü§ñ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –ò–ò:",
        reply_markup=InlineKeyboardMarkup(keyboard)
    )


async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏"""
    query = update.callback_query
    model_id = query.data
    user_sessions[query.from_user.id] = model_id

    # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {query.from_user.id} –≤—ã–±—Ä–∞–ª {model_id}")

    await query.edit_message_text(
        f"‚úÖ {MODELS[model_id]['description']}\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å..."
    )


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user = update.effective_user
    user_id = user.id

    if user_id not in user_sessions:
        await start(update, context)
        return

    model_id = user_sessions[user_id]
    model = MODELS[model_id]
    processing_msg = await update.message.reply_text(f"‚è≥ {model['name']} –¥—É–º–∞–µ—Ç...")

    # –ó–∞–ø—É—Å–∫ –∞–Ω–∏–º–∞—Ü–∏–∏
    animation_task = asyncio.create_task(
        animate_typing(update, context, processing_msg.message_id, model['name'])
    )

    try:
        response = await get_model_response(model_id, update.message.text)
        animation_task.cancel()

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π —É–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
        formatted_response = (
            f"ü§ñ *{model['name']}* –æ—Ç–≤–µ—á–∞–µ—Ç:\n\n"
            f"{response}\n\n"
            f"_{model['description'].split('\n')[0]}_"
        )

        await context.bot.edit_message_text(
            formatted_response,
            chat_id=update.message.chat_id,
            message_id=processing_msg.message_id,
            parse_mode="Markdown"
        )

        # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
        logger.info(f"–û—Ç–≤–µ—Ç {model_id} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}")

    except Exception as e:
        error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}"
        await context.bot.edit_message_text(
            error_msg,
            chat_id=update.message.chat_id,
            message_id=processing_msg.message_id
        )
        logger.error(f"–û—à–∏–±–∫–∞ —É {user_id}: {error_msg}")


# --- 8. –ó–∞–ø—É—Å–∫ ---
def main():
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤
    if not os.path.exists("bot.log"):
        with open("bot.log", "w") as f:
            f.write("–õ–æ–≥ –±–æ—Ç–∞\n" + "=" * 50 + "\n")

    app = ApplicationBuilder().token(os.getenv("TELEGRAM_TOKEN")).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CallbackQueryHandler(button_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    app.run_polling()


if __name__ == "__main__":
    main()